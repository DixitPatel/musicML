{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RBM : Simple NN which uses backpropogation to minimize difference between input and activation : Minimize PDF ; We dont-\n",
    "# have labels to validate so backpropogate and minimize error in original data reconstruction using same weight \n",
    "# Good Expln : http://deeplearning4j.org/restrictedboltzmannmachine.html\n",
    "# Math'y : http://deeplearning.net/tutorial/rbm.html\n",
    "# use this to find classify unique chords  \n",
    "# fancy :If you stack multiple such RBM's over each other -> DBN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import random, pickle\n",
    "import re,itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chords = collections.defaultdict(list)\n",
    "with open('uniqueChords.txt','r') as f :\n",
    "    for idx,i in enumerate(f):\n",
    "        notes=i.split()\n",
    "        chords[idx]=notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notelist = []\n",
    "notes  = pd.read_csv('midiToNotes.txt',skiprows=2)\n",
    "for n,l in zip(notes['Note/Rest'],notes['Octave']):\n",
    "    notelist.append('%s%s'%(n,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# piano notes to number --> 0-87\n",
    "noteValues = {'C':0,'D':2,'E':4,'F':5,'G':7,'A':9,'B':11}\n",
    "accidentals = {'-':1,'#':1}\n",
    "\n",
    "chordList = {}\n",
    "for idx,notelist in chords.items():\n",
    "    an = []\n",
    "    for i,v in enumerate(notelist):\n",
    "        k = v[0]\n",
    "        c = noteValues.get(k)\n",
    "        if (v.find('-')):\n",
    "            c=c-1\n",
    "        elif (v.find('#')):\n",
    "            c=c+1 \n",
    "        d = int(re.search('\\d',v).group())\n",
    "        c = 12*d+c\n",
    "        an.append(c)\n",
    "    chordList[idx] = an\n",
    "    #allnotes = [v for k,v in an.items()]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#one hot encoding over 88 values for each note value\n",
    "stack = np.zeros((1,88))\n",
    "for idx,notes in chordList.items():\n",
    "    allBits = np.zeros((1,88))\n",
    "    for ix,i in enumerate(notes):\n",
    "        allBits[0][i] = 1\n",
    "    if idx == 0 : stack = allBits\n",
    "    else : stack = np.vstack((stack,allBits))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                         C\n",
    "                     F*      G* \n",
    "                        \n",
    "                 Bb              D* \n",
    "\n",
    "              Eb                    A* \n",
    "\n",
    "                 Ab              E\n",
    "\n",
    "                     Db      B\n",
    "                         Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding some more training examples by using notes as postion in pentatonic scale\n",
    "# circle of fifths : Major and Minor\n",
    "\n",
    "'''minorPentatonica = ['C':[],\n",
    "               'G':[],\n",
    "               'D':[],\n",
    "               'A':[''],\n",
    "               'E':[],\n",
    "               'B':[],\n",
    "               'G-':[],\n",
    "               'D-':[],\n",
    "               'A-':[],\n",
    "               'E-':[],\n",
    "               'B-':[],\n",
    "               'F':[]\n",
    "              ]\n",
    "              '''\n",
    "def genAltered(note='C3'):\n",
    "    # In case you have to convert a note (e.g. F#) into form below\n",
    "    def convertSharps(note):\n",
    "        pitch = ''.join([i for i in note if i.isdigit() is False])\n",
    "        enharmonic = {\"C#\" : \"D-\", \"D#\" : \"E-\", \"E#\" : \"F\", \"F#\" : \"G-\", \"G#\" : \"A-\", \"A#\" : \"B-\", \"B#\" : \"C\"}\n",
    "        if '#' in pitch: return enharmonic[pitch]\n",
    "        return pitch\n",
    "    \n",
    "    # Get scale with dictionary. For example: allscales[note[:-1]]\n",
    "    allscales = {\n",
    "        \"C\"  : [\"C3\", \"E-3\", \"F3\", \"G3\", \"B-3\",\n",
    "                \"C4\", \"E-4\", \"F4\", \"G4\", \"B-4\",\n",
    "                \"C5\", \"E-5\", \"F5\", \"G5\", \"B-5\",\n",
    "                \"C6\", \"E-6\", \"F6\", \"G6\", \"B-6\"],\n",
    "        \"D-\" : [\"D-3\", \"E3\", \"G-3\", \"A-3\", \"B3\",\n",
    "                \"D-4\", \"E4\", \"G-4\", \"A-4\", \"B4\",\n",
    "                \"D-5\", \"E5\", \"G-5\", \"A-5\", \"B5\",\n",
    "                \"D-6\", \"E6\", \"G-6\", \"A-6\", \"B6\"],\n",
    "        \"D\"  : [\"C3\", \"D3\", \"F3\", \"G3\", \"A3\", \n",
    "                \"C4\", \"D4\", \"F4\", \"G4\", \"A4\", \n",
    "                \"C5\", \"D5\", \"F5\", \"G5\", \"A5\", \n",
    "                \"C6\", \"D6\", \"F6\", \"G6\", \"A6\"],\n",
    "        \"E-\" : [\"D-3\", \"E-3\", \"G-3\", \"A-3\", \"B-3\",\n",
    "                \"D-4\", \"E-4\", \"G-4\", \"A-4\", \"B-4\",\n",
    "                \"D-5\", \"E-5\", \"G-5\", \"A-5\", \"B-5\",\n",
    "                \"D-6\", \"E-6\", \"G-6\", \"A-6\", \"B-6\"],\n",
    "        \"E\"  : [\"D3\", \"E3\", \"G3\", \"A3\", \"B3\",\n",
    "                \"D4\", \"E4\", \"G4\", \"A4\", \"B4\",\n",
    "                \"D5\", \"E5\", \"G5\", \"A5\", \"B5\",\n",
    "                \"D6\", \"E6\", \"G6\", \"A6\", \"B6\"],\n",
    "        \"F\"  : [\"C3\", \"E-3\", \"F3\", \"A-3\", \"B-3\",\n",
    "                \"C4\", \"E-4\", \"F4\", \"A-4\", \"B-4\",\n",
    "                \"C5\", \"E-5\", \"F5\", \"A-5\", \"B-5\",\n",
    "                \"C6\", \"E-6\", \"F6\", \"A-6\", \"B-6\"],\n",
    "        \"G-\" : [\"D-3\", \"E3\", \"G-3\", \"A3\", \"B3\",\n",
    "                \"D-4\", \"E4\", \"G-4\", \"A4\", \"B4\",\n",
    "                \"D-5\", \"E5\", \"G-5\", \"A5\", \"B5\",\n",
    "                \"D-6\", \"E6\", \"G-6\", \"A6\", \"B6\"],\n",
    "        \"G\"  : [\"C3\", \"D3\", \"F3\", \"G3\", \"B-3\",\n",
    "                \"C4\", \"D4\", \"F4\", \"G4\", \"B-4\",\n",
    "                \"C5\", \"D5\", \"F5\", \"G5\", \"B-5\",\n",
    "                \"C6\", \"D6\", \"F6\", \"G6\", \"B-6\"],\n",
    "        \"A-\" : [\"D-3\", \"E-3\", \"G-3\", \"A-3\", \"B3\",\n",
    "                \"D-4\", \"E-4\", \"G-4\", \"A-4\", \"B4\",\n",
    "                \"D-5\", \"E-5\", \"G-5\", \"A-5\", \"B5\",\n",
    "                \"D-6\", \"E-6\", \"G-6\", \"A-6\", \"B6\"],\n",
    "        \"A\"  : [\"C3\", \"D3\", \"E3\", \"G3\", \"A3\",\n",
    "                \"C4\", \"D4\", \"E4\", \"G4\", \"A4\",\n",
    "                \"C5\", \"D5\", \"E5\", \"G5\", \"A5\",\n",
    "                \"C6\", \"D6\", \"E6\", \"G6\", \"A6\"],\n",
    "        \"B-\" : [\"D-3\", \"E-3\", \"F3\", \"A-3\", \"B-3\",\n",
    "                \"D-4\", \"E-4\", \"F4\", \"A-4\", \"B-4\",\n",
    "                \"D-5\", \"E-5\", \"F5\", \"A-5\", \"B-5\",\n",
    "                \"D-6\", \"E-6\", \"F6\", \"A-6\", \"B-6\"],\n",
    "        \"B\"  : [\"D3\", \"E3\", \"G-3\", \"A3\", \"B3\",\n",
    "                \"D4\", \"E4\", \"G-4\", \"A4\", \"B4\",\n",
    "                \"D5\", \"E5\", \"G-5\", \"A5\", \"B5\",\n",
    "                \"D6\", \"E6\", \"G-6\", \"A6\", \"B6\"]}\n",
    "    pitch = ''.join([i for i in note if i.isdigit() is False])\n",
    "    pitch = convertSharps(note) # Rm. octaveinfo, eg. G-5 --> G-, G5->G\n",
    "    return allscales[pitch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2001, 88)\n",
      "(2040,)\n"
     ]
    }
   ],
   "source": [
    "def quantify(note):\n",
    "    notevals = {\n",
    "        'C' : 0,\n",
    "        'D' : 2,\n",
    "        'E' : 4,\n",
    "        'F' : 5,\n",
    "        'G' : 7,\n",
    "        'A' : 9,\n",
    "        'B' : 11\n",
    "    }\n",
    "    quantized = 0\n",
    "    octave = int(note[-1]) - 1\n",
    "    for i in note[:-1]:\n",
    "        if i in notevals: quantized += notevals[i]\n",
    "        if i == '-': quantized -= 1\n",
    "        if i == '#': quantized += 1\n",
    "    quantized += 12 * octave\n",
    "    return quantized\n",
    "\n",
    "def genChordNotes(chord):\n",
    "    notevect = np.zeros((1, 88))\n",
    "    \n",
    "    # populate with initial pitches\n",
    "    for note in chord:\n",
    "        notevect[0, quantify(note)] = 1\n",
    "        \n",
    "    # add initial pitches transposed to other octaves\n",
    "    otheroctaves = range(3, 6)\n",
    "    for note in chord:\n",
    "        notebase = note[:-1]\n",
    "        for octv in otheroctaves:\n",
    "            put = bool(random.getrandbits(1)) # randomize other pitches\n",
    "            if put is True:\n",
    "                translated = \"%s%s\" % (notebase, octv)\n",
    "                notevect[0, quantify(translated)] = 1\n",
    "    altfreqs = defaultdict(int)\n",
    "    for note in chord:\n",
    "        for i in genAltered(note):\n",
    "            altfreqs[i] += 1\n",
    "    topnotes = [k for k, v in altfreqs.items() if v > 2] # get notes that overlap > 2 times\n",
    "    for note in topnotes: # flip bits randomly from this list\n",
    "        if bool(random.getrandbits(1)):\n",
    "            notevect[0, quantify(note)] = 1\n",
    "    \n",
    "    # return the vector\n",
    "    return notevect\n",
    "\n",
    "more_x = np.zeros((1, 88))\n",
    "more_y = [k for k,v in chords.items()]\n",
    "for chordID, chord in chords.items():\n",
    "    for j in range(50): \n",
    "        more_x = np.vstack((more_x, genChordNotes(chord)))\n",
    "        more_y.append(chordID)\n",
    "more_y = np.array(more_y).reshape((-1))       \n",
    "print(more_x.shape)\n",
    "print(more_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = np.delete(more_x,0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 88)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more_x = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 39, 39, 39])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 88)\n",
      "(2040,)\n",
      "2040\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((stack,more_x))\n",
    "n_samples,x = X.shape\n",
    "#ydata = [k for k,v in chords.items()]\n",
    "#y = np.array(ydata)\n",
    "y = more_y\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 39, 39, 39])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100,1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100,1000]}]\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.003 (+/-0.009) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.003 (+/-0.009) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.796 (+/-0.035) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.003 (+/-0.009) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.923 (+/-0.027) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.796 (+/-0.035) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.915 (+/-0.032) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.921 (+/-0.028) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "0.915 (+/-0.020) for {'kernel': 'linear', 'C': 1}\n",
      "0.915 (+/-0.021) for {'kernel': 'linear', 'C': 10}\n",
      "0.914 (+/-0.025) for {'kernel': 'linear', 'C': 100}\n",
      "0.912 (+/-0.026) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       0.67      0.80      0.73        10\n",
      "          2       0.77      1.00      0.87        17\n",
      "          3       1.00      1.00      1.00        18\n",
      "          4       1.00      0.94      0.97        18\n",
      "          5       1.00      0.94      0.97        16\n",
      "          6       0.67      0.29      0.40        14\n",
      "          7       0.82      1.00      0.90        14\n",
      "          8       1.00      1.00      1.00        20\n",
      "          9       0.53      0.47      0.50        19\n",
      "         10       0.46      0.40      0.43        15\n",
      "         11       1.00      0.43      0.60        14\n",
      "         12       0.60      1.00      0.75        12\n",
      "         13       0.56      0.71      0.63        14\n",
      "         14       1.00      0.93      0.96        14\n",
      "         15       1.00      0.95      0.97        19\n",
      "         16       0.87      1.00      0.93        13\n",
      "         17       1.00      0.94      0.97        18\n",
      "         18       1.00      0.94      0.97        18\n",
      "         19       1.00      0.94      0.97        16\n",
      "         20       1.00      1.00      1.00        15\n",
      "         21       1.00      1.00      1.00        12\n",
      "         22       1.00      0.94      0.97        16\n",
      "         23       1.00      1.00      1.00        16\n",
      "         24       1.00      0.91      0.95        11\n",
      "         25       1.00      1.00      1.00        15\n",
      "         26       0.90      1.00      0.95        18\n",
      "         27       0.91      0.50      0.65        20\n",
      "         28       0.55      0.92      0.69        13\n",
      "         29       0.88      1.00      0.94        15\n",
      "         30       1.00      0.94      0.97        16\n",
      "         31       1.00      0.94      0.97        16\n",
      "         32       1.00      1.00      1.00        14\n",
      "         33       0.79      1.00      0.88        11\n",
      "         34       1.00      0.92      0.96        13\n",
      "         35       0.84      1.00      0.91        16\n",
      "         36       1.00      1.00      1.00        18\n",
      "         37       1.00      0.93      0.97        15\n",
      "         38       1.00      1.00      1.00        11\n",
      "         39       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.90      0.89      0.88       612\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.041 (+/-0.061) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.041 (+/-0.061) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.812 (+/-0.023) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.041 (+/-0.061) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.911 (+/-0.022) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.812 (+/-0.023) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.908 (+/-0.028) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.909 (+/-0.022) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "0.909 (+/-0.018) for {'kernel': 'linear', 'C': 1}\n",
      "0.908 (+/-0.021) for {'kernel': 'linear', 'C': 10}\n",
      "0.908 (+/-0.024) for {'kernel': 'linear', 'C': 100}\n",
      "0.906 (+/-0.025) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       0.67      0.80      0.73        10\n",
      "          2       0.77      1.00      0.87        17\n",
      "          3       1.00      1.00      1.00        18\n",
      "          4       1.00      0.94      0.97        18\n",
      "          5       1.00      0.94      0.97        16\n",
      "          6       0.67      0.29      0.40        14\n",
      "          7       0.82      1.00      0.90        14\n",
      "          8       1.00      1.00      1.00        20\n",
      "          9       0.53      0.47      0.50        19\n",
      "         10       0.46      0.40      0.43        15\n",
      "         11       1.00      0.43      0.60        14\n",
      "         12       0.60      1.00      0.75        12\n",
      "         13       0.56      0.71      0.63        14\n",
      "         14       1.00      0.93      0.96        14\n",
      "         15       1.00      0.95      0.97        19\n",
      "         16       0.87      1.00      0.93        13\n",
      "         17       1.00      0.94      0.97        18\n",
      "         18       1.00      0.94      0.97        18\n",
      "         19       1.00      0.94      0.97        16\n",
      "         20       1.00      1.00      1.00        15\n",
      "         21       1.00      1.00      1.00        12\n",
      "         22       1.00      0.94      0.97        16\n",
      "         23       1.00      1.00      1.00        16\n",
      "         24       1.00      0.91      0.95        11\n",
      "         25       1.00      1.00      1.00        15\n",
      "         26       0.90      1.00      0.95        18\n",
      "         27       0.91      0.50      0.65        20\n",
      "         28       0.55      0.92      0.69        13\n",
      "         29       0.88      1.00      0.94        15\n",
      "         30       1.00      0.94      0.97        16\n",
      "         31       1.00      0.94      0.97        16\n",
      "         32       1.00      1.00      1.00        14\n",
      "         33       0.79      1.00      0.88        11\n",
      "         34       1.00      0.92      0.96        13\n",
      "         35       0.84      1.00      0.91        16\n",
      "         36       1.00      1.00      1.00        18\n",
      "         37       1.00      0.93      0.97        15\n",
      "         38       1.00      1.00      1.00        11\n",
      "         39       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.90      0.89      0.88       612\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#scikit\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('classifier.pickle','wb') as f :\n",
    "    pickle.dump(clf.best_estimator_,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('chords.pickle','wb') as f:\n",
    "    pickle.dump(chords,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
